
Documents about King Fukaura
 
King Fukaura started development in December 2020 as a dlshogi compatible engine.
 
 
■ About dlshogi
 
 
--dlshogi GitHub: https://github.com/TadaoYamaoka/DeepLearningShogi
--Tadao Yamaoka's diary: https://tadaoyamaoka.hatenablog.com/
 
--Dlshogi environment construction procedure
 --Linux // dlshogi environment construction procedure: https://tadaoyamaoka.hatenablog.com/entry/2020/05/05/172132 
 --Linux // Run dlshogi on AWS NVIDIA A100 instance: https://tadaoyamaoka.hatenablog.com/entry/2020/11/07/154352
 --WSL 2 //
 // From k_kanou
 // CUDA on WSL 2 was also able to build the environment of dlshogi.
 // With NVIDIA Drivers for CUDA on WSL, it is important to note that the cuda library is placed below.
 // /usr/lib/wsl/lib/libcuda.so.1
 --Waiting CUDA on WSL 2: https://qiita.com/ksasaki/items/ee864abd74f95fea1efa
 --Windows:
--ONNX RUNTIME version should work with Windows standard. Although the performance is inferior.
 --Try using ONNX Runtime: https://tadaoyamaoka.hatenablog.com/entry/2020/05/26/233159
 > dlshogi requires a Nvidia GPU that supports CUDA, but I would like to be able to run it only with AMD's GPU and CPU.
 --Try using ONNX Runtime Part 2 (Performance measurement): https://tadaoyamaoka.hatenablog.com/entry/2020/06/06/190259
 --Try using ONNX Runtime Part 3 (DirectML): https://tadaoyamaoka.hatenablog.com/entry/2020/06/07/113616
 
 // Also, "DirectML.dll" seems to be needed at runtime for some reason.
 // According to the above article "Part 3 (DirectML)", it seems that it is good to copy from the executable file of dlshogi.
 // World Shogi AI Denryu Battle Version (included with "GCT Denryu"): https://github.com/TadaoYamaoka/DeepLearningShogi/releases/tag/denryu2020
 
 --Tensor RT version
 --World Shogi AI Denryu Battle Version (included with "GCT Denryu"): https://github.com/TadaoYamaoka/DeepLearningShogi/releases/tag/denryu2020
 // TensorRT seems to optimize CUDA and also requires CUDA's Toolkit.
 
 --CUDA Toolkit 11.0 Download: https://developer.nvidia.com/cuda-11.0-download-archive
 --Run TensorRT on Windows: https://tadaoyamaoka.hatenablog.com/entry/2020/04/12/155648
 > According to the release notes, performance seems to drop by 30% on Windows.
 > It is written that if you change to TCC mode, it will be suppressed to 10%
 --Install TensorRT
――It seems that you need to register as a member by clicking download from ↓. As of December 18, 2020, TensorRT 7.2.1 is the latest.
 --https://developer.nvidia.com/tensorrt
 --TensorRT7 download (after membership registration): https://developer.nvidia.com/nvidia-tensorrt-7x-download
 --NVIDIA TENSORRT DOCUMENTATION: https://docs.nvidia.com/deeplearning/tensorrt/archives/index.html#trt_7
 
 --cuDNN 8.0.5 Download (after membership registration): https://developer.nvidia.com/rdp/cudnn-download
 > Download cuDNN v8.0.5 (November 9th, 2020), for CUDA 11.1
→ dlshogi and cuDNN are no longer needed. [2021/1/25]
 
 
■ About Aoba Zero
 
 
--Aoba Zero official website: http://www.yss-aya.com/aobazero/
--Aoba Zero's GitHub: https://github.com/kobanium/aobazero
--Game record generated by Aoba Zero (Google Drive): https://drive.google.com/drive/folders/1dbE5xWGQLsduR00oxEGPpZQJtQr_EQ75
――It is added every day. It can be used as it is as a teacher game record. Thank you.
 
--Processing of Aoba Zero's game record: https://tadaoyamaoka.hatenablog.com/entry/2020/11/28/113312
 --Correct the winning / losing information of Aoba Zero's game record by calling 5 steps.
 
--aboba_to_hcpe.py: https://github.com/TadaoYamaoka/DeepLearningShogi/blob/master/utils/aoba_to_hcpe.py
 --Aoba Zero game record processing script
 --Script using cshogi.
> 711 Files have been converted. It took 4 hours and 43 minutes to convert.
 // 5 squeeze
 --I want to parallelize & call df-pn, so YaneuraOu will implement the equivalent independently.
 
 
■ About dlshogi's book generation procedure
 
 
https://github.com/TadaoYamaoka/DeepLearningShogi/tree/master/usi
 
 
-DMAKE_BOOK
Build with
 
./usi
setoption name DNN_Model value /home/ubuntu/model-0000167.onnx
setoption name UCT_Threads value 3
setoption name UCT_Threads2 value 3
setoption name UCT_Threads3 value 3
setoption name UCT_Threads4 value 3
setoption name UCT_Threads5 value 3
setoption name UCT_Threads6 value 3
setoption name UCT_Threads7 value 3
setoption name UCT_Threads8 value 3
setoption name Save_Book_Interval value 100
isready
make_book [bookFileName] [outFileName] [playoutNum] [limitTrialNum]
 
*
Save_Book_Interval is the interval to save in the middle (default 100)
bookFileName specifies the book used by the opponent.
outFileName is created if there is no file. If it already exists, it will be searched from the continuation.
playoutNum is 10000000 (10 million)
limitTrialNum is 500
And I run it as many times as I have time.
Basically, I'm searching as much as memory allows.
 
 
In ruby ​​script
 
https://github.com/TadaoYamaoka/shogi-server/blob/master/bin/usiToCsa_denryu
UCT_NodeLimit = 50000000
I may think about 3 minutes in production, so I made it large enough not to be hashfull.
GitHub
Tadao Yamaoka / Deep Learning Shogi
Contribute to TadaoYamaoka / DeepLearningShogi development by creating an account on GitHub.
 
GitHub
TadaoYamaoka / shogi-server
Contribute to TadaoYamaoka / shogi-server development by creating an account on GitHub.
 
 
 
■ Learning method
 
 
// Summary
--Snamp SoTA! Shock optimizer "SAM" explosion & commentary! : https://qiita.com/omiita/items/f24e4f06ae89115d248e
 
 
■ About the randomness of the move
 
 
――With PUCT, there is no randomness in the move, and it is easy to get the same game record in self-play.
 
--In dlshogi, Dirichlet noise is used during reinforcement learning to give randomness.
--Deep learning with shogi Part 51 (Dirichlet noise): https://tadaoyamaoka.hatenablog.com/?page= 1515162256
 
 
■ Procedure for building a learning environment for dlshogi Windows native environment
 
 
--For Windows environment, see GCT's notebook by Mr. Kano.
 GCT (Google Colab TPU Training) Shogi: https://gist.github.com/lvisdd/9b49ab88600fa242f2138fad4eb06caf
 dlshogi-DenryuSen-resnet10_swish-amp.ipynb: https://colab.research.google.com/drive/1beq7ncmE16lIvOhGTHLzxOwaQNzAcUqh?usp=sharing
 
 
■ Procedure for building a learning environment for dlshogi How to use WSL2 + Ubuntu 20.04 in a Windows environment
 
 
* There was a problem that GPU was not available on WSL2, but it was fixed in build 20236.
* WSL2 is currently required to be downloaded from the Windows Insider Program.
 
 
・ Until Ubuntu is installed
 
 #Windows Settings-Updates and Security-Join the Windows Insider Program, set up to subscribe to Dev channels and update Windows
 
 // Reference article)
 // I've been waiting for you CUDA on WSL 2
 // https://qiita.com/ksasaki/items/ee864abd74f95fea1efa
 
 # PowerShell ("Win" + "X" key or right-click or long-press tap "Windows Start Button") → (Select "I" key or "Windows PowerShell (I)") to start
 
# Create a folder called "c: \ wsl" on the C drive. (I'm running Ubuntu 20.04 from now on)
 mkdir C: \ WSL
 cd C: \ WSL
 
 ## Make sure the version number is Windows 10.0.20236. * or later (as of February 6, 2021 only available on Insider Preview, Dev Channel)
 cmd / c ver
 
 // Download TensorRT and CUDA drivers
 
 ## Select "Tensor RT 7.2.2 for Ubuntu 18.04 and CUDA 11.1 & 11.2 DEB local repo package" from the following page and download it to "C: \ WSL"
 start https://developer.nvidia.com/nvidia-tensorrt-7x-download
 // The file name should be → "nv-tensorrt-repo-ubuntu1804-cuda11.1-trt7.2.2.3-ga-20201211_1-1_amd64.deb".
 
 # Download CUDA driver
 curl.exe -RLO https://developer.download.nvidia.com/compute/cuda/11.2.0/local_installers/cuda-repo-wsl-ubuntu-11-2-local_11.2.0-1_amd64.deb curl.exe- RLO https://developer.download.nvidia.com/compute/cuda/11.1.1/local_installers/cuda-repo-wsl-ubuntu-11-1-local_11.1.1-1_amd64.deb
 curl.exe -RLO https://developer.download.nvidia.com/compute/cuda/11.2.0/local_installers/cuda-repo-wsl-ubuntu-11-2-local_11.2.0-1_amd64.deb
// If only "curl" is used, it will accidentally explode in PowerShell alias. You have to write "curl.exe".
 
 ## Open the NVIDIA CUDA on WSL Public Preview information page in your browser
 ## Follow the link button of "Get CUDA Driver" to get and install the WSL compatible driver.
 start https://developer.nvidia.com/cuda/wsl
 // "465.42_gameready_win10-dch_64bit_international.exe"
 // Run this on the Windows side to install.
 
 ## Check the version of NVIDIA Driver (as of February 6, 2021, the version of the WSL compatible driver is 465.42)
 nvidia-smi
 
 ## (if you are not on the Dev Channel)
 ## Settings: Open the Windows Insider Program.
 ## Once the settings are open, join the Dev Channel of the Windows Insider Program.
 ## If you can't open "Settings-Windows Insider Program" with the command below:
 ##-"Win" + "X" key → "N" key to open "Settings"
 ##-"Settings"-> ("Home"->) "Update and Security"-> "Windows Insider Program"
 start ms-settings: windowsinsider
 
 
 ## Install WSL Ubuntu-20.04 (administrator privileges required)
 wsl --install -d Ubuntu-20.04
 // Reboot is required after this.
 // Reboot to start installing Ubuntu.
 
 ## "Enter new UNIX username:" Enter username for Ubuntu-20.04
 ## "New password:" Enter the password for Ubuntu-20.04
 ## "Retype new password:" Enter the password for Ubuntu-20.04 again
 ## Success if "Installation succesful!" Is displayed
 
 // ## Temporarily terminate WSL Ubuntu-20.04
 // exit
 
・ How to start WSL from the next time onwards
 
 // # PowerShell Example: "Win" + "X" key → Start with "I" key
 
 ## Start WSL Ubuntu-20.04
 wsl -d Ubuntu-20.04 --cd ~
 
 // ## Shut down WSL (to prevent troubles such as not being able to connect to the network in the following steps)
 // wsl --shutdown
 
 // ## WSL Ubuntu-20.04 unregistered
 // wsl --unregister Ubuntu-20.04
 // ## Start Ubuntu-20.04
 // # WSL Ubuntu-20.04
 
 
・ Build TensorRT and CUDA environment in WSL Ubuntu-20.04
 
 # WSL Ubuntu-20.04
 ## Ubuntu APT Mirrors
 ## Ubuntu new / update package Allows package update via mirror site to reduce installation time.
 ## When executing a command starting with sudo, you may be asked for a password, so enter the password you set earlier.
 sudo sed -i.bak -r's! (deb | deb-src) http://archive \ .ubuntu \ .com / \ S +! \ 1 mirror: //mirrors.ubuntu.com/mirrors.txt!' /etc/apt/sources.list
 ## Preparation for CUDA introduction
 curl -RLO https://developer.download.nvidia.com/compute/cuda/repos/wsl-ubuntu/x86_64/cuda-wsl-ubuntu.pin
 sudo mv cuda-wsl-ubuntu.pin /etc/apt/preferences.d/cuda-repository-pin-600
 sudo apt-key adv --fetch-keys https://developer.download.nvidia.com/compute/cuda/repos/wsl-ubuntu/x86_64/7fa2af80.pub
 ## CUDA 11.1.1 for Linux WSL-Ubuntu local repos
 sudo dpkg -i / mnt / c / WSL / cuda-repo-wsl-ubuntu-11-1-local_11.1.1-1_amd64.deb
 sudo apt-key add /var/cuda-repo-wsl-ubuntu-11-1-local/7fa2af80.pub
 ## CUDA 11.2.0 for Linux WSL-Ubuntu local repos
 sudo dpkg -i /mnt/c/WSL/cuda-repo-wsl-ubuntu-11-2-local_11.2.0-1_amd64.deb
 sudo apt-key add /var/cuda-repo-wsl-ubuntu-11-2-local/7fa2af80.pub
 ## TensorRT 7.2.2 for Linux DEB local repos
 sudo dpkg -i /mnt/c/WSL/nv-tensorrt-repo-ubuntu1804-cuda11.1-trt7.2.2.3-ga-20201211_1-1_amd64.deb
 sudo apt-key add /var/nv-tensorrt-repo-cuda11.1-trt7.2.2.3-ga-20201211/7fa2af80.pub
 ## Install APT package
 sudo apt-get update
 sudo apt-get -y install cuda curl tensorrt build-essential g ++-10 unzip libboost-numpy-dev libboost-python-dev libboost-system-dev python3-pip
 ## Add NVIDIA repository online
 sudo add-apt-repository "deb https://developer.download.nvidia.com/compute/cuda/repos/wsl-ubuntu/x86_64/ /"
 ## Update APT package
 sudo apt-get update
 sudo apt-get -y upgrade
 
 
・ Dlshogi, until learning the evaluation function equivalent to GCT of the 2020 Denryu battle, learning the book
 
 pushd ~
 curl -RLO https://github.com/TadaoYamaoka/DeepLearningShogi/releases/download/denryu2020/gct-dlshogi-denryu2020.zip
 popd
 mkdir ~ / eval
 mkdir ~ / book
 unzip ~ / gct-dlshogi-denryu2020.zip * .onnx -d ~ / eval
 unzip ~ / gct-dlshogi-denryu2020.zip book.bin -d ~ / book
 cp ~ / eval / model-0000167.onnx ~ / eval / model.onnx
 # yaneuraou deep
 git clone https://github.com/yaneurao/YaneuraOu.git ~ / YaneuraOu
 pushd ~ / YaneuraOu / source
 export LD_LIBRARY_PATH = / usr / local / cuda / lib64: / usr / lib / wsl / lib: / usr / lib / x86_64-linux-gnu
 make YANEURAOU_EDITION = YANEURAOU_ENGINE_DEEP_TENSOR_RT clean
 nice make -j $ (grep -c processor / proc / cpuinfo) YANEURAOU_EDITION = YANEURAOU_ENGINE_DEEP_TENSOR_RT TARGET_CPU = AVX2 COMPILER = g ++ -10 EXTRA_CPPFLAGS ='-I / usr / local / cuda / include'EXTRA_LDFLAGS ='-L / usr / local cuda / lib64 -L / usr / lib / wsl / lib'normal
 popd
 # dlshogi
 pip3 install torch == 1.7.1 + cu110 torchvision = = 0.8.2 + cu110 torchaudio == = 0.7.2 -f https://download.pytorch.org/whl/torch_stable.html
 git clone https://github.com/TadaoYamaoka/DeepLearningShogi.git ~ / DeepLearningShogi
 pushd ~
 curl -RLO https://gist.githubusercontent.com/mizar/1f36c8c456926460bc8585e2fc631bd7/raw/8b7e831b7570b5165f8ca2425643b4837e88e4a0/dlshogi.diff
 popd
 pushd ~ / DeepLearningShogi
 git apply ~ / dlshogi.diff
 pip3 install --no-cache-dir -e.
 pip3 install cshogi
 popd
 pushd ~ / DeepLearningShogi / make_hcpe_by_self_play
 make clean
 nice make -j $ (grep -c processor / proc / cpuinfo)
 popd
 pushd ~ / DeepLearningShogi / cppshogi
 make clean
 nice make -j $ (grep -c processor / proc / cpuinfo)
 popd
 pushd ~ / DeepLearningShogi/usi
 make clean
 nice make -j $ (grep -c processor / proc / cpuinfo)
 popd
 
// By Mizar's patch above, specify "--network" in the training script (train_rl_policy_with_value_using_hcpe_bootstrap.py) to dynamically change the model structure.
// Can be changed.
// cf. https://github.com/mizar/dlshogi/tree/feature/network
// * Currently private
 
 
・ Example of initial learning (without inheriting model and state files)
 // Compared to continuous learning, -m [previous model name] and -r [previous state name] are not specified.
 wsl.exe -d Ubuntu-20.04 python3 ~ / DeepLearningShogi / dlshogi / train_rl_policy_with_value_using_hcpe_bootstrap.py teach_d12_suisho2_20201010_hcpe / teach_d12_suisho2_20201010.hcpe.0000 teach_d18_sui -0000 --use_amp --log resnet10_swish / log / log.0000 --lr 0.001 --swa_lr 0.001
 
-Example of continuous learning (with inheritance of model and state files) (If you omit the specification with the -r option only for the state file, you can also inherit only the model file for learning)
 wsl.exe -d Ubuntu-20.04 python3 ~ / DeepLearningShogi / dlshogi / train_rl_policy_with_value_using_hcpe_bootstrap.py teach_d12_suisho2_20201010_hcpe / teach_d12_suisho2_20201010.hcpe.0001 teach_d18_sui --model resnet10_swish / model / model-0001 --state resnet10_swish / model / state-0001 --use_amp --log resnet10_swish / log / log.0001 --lr 0.001 --swa_lr 0.001
 
-Example of ONNX conversion of model file
 wsl.exe -d Ubuntu-20.04 python3 ~ / DeepLearningShogi / dlshogi / convert_model_to_onnx.py --network resnet10_swish resnet10_swish / model / model-0000 resnet10_swish / model / model-0000.onnx
 
> python3 ~ / DeepLearningShogi / dlshogi / train_rl_policy_with_value_using_hcpe_bootstrap.py hcpe / floodgate_teacher_uniq-test-01 hcpe --network resnet15ch192_swish --model resnet15swish / model / model-0000 --state resnet15swish / model / state-0000 --state resnet15swish / model / state /log/log.0000 --lr 0.001 --swa_lr 0.001
 
 
 
 
# First time
# get dlshogi fork
pushd ~ / Deep Learning Shogi /
git remote add mizar https://github.com/mizar/dlshogi.git
## For the password required by git fetch via https, enter the access token instead of the password for your GitHub account.
## cf. https://docs.github.com/ja/github/authenticating-to-github/creating-a-personal-access-token
git fetch mizar
git checkout mizar / feature / network -b feature / network
popd
 
 
# From the second time onwards, at the time of update
# reset to HEAD of mizar / feature / network
pushd ~ / Deep Learning Shogi /
git fetch mizar
git reset --hard mizar / feature / network
popd
 
 
■ How to read the learning log of dlshogi
 
 
For example, the following is recorded in the log file generated during learning.
 
 2021/02/17 19:47:01 INFO epoch = 103, iteration = 951633, train loss avr = 0.65656561, 0.55363852, 0.77022078, 1.28232603, test_loss = 0.87752425, 0.56018966, 0.60538296, 1.45276328, test accuracy = 0.44430245, 0.72181578, test entropy = 1.51603591, 0.64071724
 
Mr. Yamaoka taught me the meaning of each of these.
 
 The four losses are policy, value (reward), Q value (expected value of search result), and total.
 accuracy is the correct answer rate of policy and value, respectively.
 test entropy is the entropy of policy and value (how much the values ​​are scattered) when inferring the test phase.
 
 
■ Utilization of Google Colab
 
 
Google Colab is now CUDA 11.0 compliant, so it seems to work a lot.
 
 How to run dlshogi build / self-play (generate teacher phase) on Linux (Kano's note)
 https://colab.research.google.com/drive/14R6rKkBVVZ_lv78h97zC9Zan62KQok-b?usp=sharing
 
 
■ Materials for those who participate in the tournament as King Fukaura
 
 
--Caution for those who participate in the tournament as King Fukaura
 
 --Assuming that you will borrow A100 * 8, set the engine options as follows.
 
 "MaxMovesToDraw" → WCSC seems to be a 320 draw, so I decided to go to 322 for safety.
 
"UCT_NodeLimit" → About 100 million. (Set according to the installed memory)
 
 // Assuming that you use the model file of ResNet10 block,
 "UCT_Threads1" → 4 or 5 is probably the best.
 "DNN_Batch_Size1" → 128 is the best.
 "LeafDfpnNodesLimit" → Memory bandwidth will be exhausted if it is only about 40.
 "RootMateSearchNodesLimit" → Default 1 million
 Since it is not stored in the memory when the drawing is done, if you raise this value → Tsume shogi is solved → Ogoma is just thrown away → The opponent points
 → You may not have enough time to find a checkmate and you may self-destruct.
 I think that the value in the range that can be absolutely solved with the minimum time (2 seconds) is better.
 // Should be a comparative experiment
 
 // Time control
 "Stochastic_Ponder" → true
 "SlowMover" → 100
 
 // Sennichite breakthrough
 
"DrawValueBlack" → If you want to break through Sennichite, both 496. If you want to aim for Sennichite, it's about 520.
 "DrawValueWhite"
 (* Evaluation value can be converted to win rate by sigmoid function. Evaluation value -10 is 1 / (1 + EXP (--10 / 600)) == 0.495833)
